# Torch.Compile Error Fix: _act_scale Cache Issue

## ğŸ› é”™è¯¯ä¿¡æ¯

```
File "/home/jz97/VLM_REPO/openpi/src/openpi/models_pytorch/duquant_layers.py", line 252, in forward
    s_a = self._get_act_scale(x_t)
  File "/home/jz97/VLM_REPO/openpi/src/openpi/models_pytorch/duquant_layers.py", line 238, in _get_act_scale
    self._act_scale = scale.to(dtype=x.dtype, device=x.device)

To prevent overwriting, clone the tensor outside of torch.compile()
or call torch.compiler.cudagraph_mark_step_begin() before each model invocation.
```

## ğŸ” åŸå› åˆ†æ

### é—®é¢˜æœ¬è´¨

**Torch.compileä¸å…è®¸åœ¨ç¼–è¯‘çš„å‡½æ•°å†…ç›´æ¥ä¿®æ”¹æ¨¡å—çš„å±æ€§ï¼ˆmutationï¼‰**

åœ¨ `_get_act_scale()` æ–¹æ³•ä¸­ï¼š
```python
# Line 228 & 238
self._act_scale = scale.to(dtype=x.dtype, device=x.device)
```

è¿™è¡Œä»£ç åœ¨ `forward()` å‡½æ•°è¢« `torch.compile()` ç¼–è¯‘åï¼Œå°è¯•ä¿®æ”¹ `self._act_scale`ï¼Œè¿åäº†torch.compileçš„é™åˆ¶ã€‚

### Torch.Compileçš„é™åˆ¶

1. **ä¸å…è®¸mutation**ï¼šç¼–è¯‘åçš„å‡½æ•°ä¸èƒ½ä¿®æ”¹æ¨¡å—çš„state
2. **éœ€è¦functional**ï¼šæ‰€æœ‰æ“ä½œéƒ½åº”è¯¥æ˜¯pure function
3. **ç¼“å­˜ä¼šç ´ågraph**ï¼šåŠ¨æ€ä¿®æ”¹å±æ€§ä¼šå¯¼è‡´recompilation

### ä¸ºä»€ä¹ˆä¹‹å‰æ²¡æŠ¥é”™ï¼Ÿ

ä¹‹å‰ç¦ç”¨äº†torch.compileï¼š
```bash
export OPENPI_DISABLE_TORCH_COMPILE=1
```

å¯ç”¨torch.compileåï¼Œè¿™ä¸ªé—®é¢˜å°±æš´éœ²äº†ã€‚

---

## ğŸ”§ è§£å†³æ–¹æ¡ˆ

æœ‰3ç§æ–¹æ¡ˆï¼ŒæŒ‰æ¨èé¡ºåºï¼š

### æ–¹æ¡ˆ1: ä½¿ç”¨register_buffer + in-placeæ“ä½œ â­â­â­â­â­

**æœ€æ¨èï¼štorch.compileå‹å¥½ï¼Œæ€§èƒ½æœ€ä½³**

ä¿®æ”¹ `duquant_layers.py`:

```python
def __init__(self, base: nn.Linear, name: str, cfg: DuQuantConfig, ...):
    # ... åŸæœ‰ä»£ç  ...

    # æ”¹ç”¨register_bufferå­˜å‚¨act_scaleï¼ˆè€Œä¸æ˜¯æ™®é€šå±æ€§ï¼‰
    self.register_buffer("_act_scale", None)
    self._act_scale_initialized = False  # ç”¨flagè€Œä¸æ˜¯æ£€æŸ¥None

def _get_act_scale(self, x: torch.Tensor) -> torch.Tensor:
    if self.cfg.act_bits <= 0:
        return torch.ones(x.shape[-1], dtype=x.dtype, device=x.device)

    # å¦‚æœå·²åˆå§‹åŒ–ï¼Œç›´æ¥è¿”å›
    if self._act_scale_initialized:
        return self._act_scale

    # åˆå§‹åŒ–æ—¶ä½¿ç”¨no_gradå’Œin-placeæ“ä½œ
    with torch.no_grad():
        if self.calibrator is not None and not self.calibrator.is_full():
            self.calibrator.observe(x)
            if self.calibrator.is_full():
                p_vec = self.calibrator.finalize()
                max_q = qmax(self.cfg.act_bits)
                scale = torch.clamp(p_vec / max_q, min=1e-6)
                # ä½¿ç”¨copy_æ›¿ä»£ç›´æ¥èµ‹å€¼
                if self._act_scale is None:
                    self._act_scale = scale.to(dtype=x.dtype, device=x.device)
                else:
                    self._act_scale.copy_(scale.to(dtype=x.dtype, device=x.device))
                self._act_scale_initialized = True

        # Fallback
        if not self._act_scale_initialized:
            x_abs = torch.abs(x.detach().to(torch.float32))
            C = x_abs.shape[-1]
            x2d = x_abs.reshape(-1, C)
            p_vec = torch.quantile(x2d, self.cfg.act_percentile / 100.0, dim=0)
            max_q = qmax(self.cfg.act_bits)
            scale = torch.clamp(p_vec / max_q, min=1e-6)
            if self._act_scale is None:
                self._act_scale = scale.to(dtype=x.dtype, device=x.device)
            else:
                self._act_scale.copy_(scale.to(dtype=x.dtype, device=x.device))
            self._act_scale_initialized = True

    return self._act_scale
```

**ä¼˜ç‚¹ï¼š**
- âœ… Torch.compileå‹å¥½
- âœ… æ€§èƒ½æœ€ä½³
- âœ… ä¿æŒåŸæœ‰é€»è¾‘

---

### æ–¹æ¡ˆ2: ç¦ç”¨activation quantization â­â­â­â­

**æœ€ç®€å•ï¼šæš‚æ—¶ç¦ç”¨æ¿€æ´»é‡åŒ–ï¼Œåªä¿ç•™æƒé‡é‡åŒ–**

```bash
# åœ¨run_optimized_duquant.shä¸­æ·»åŠ ï¼š
export OPENPI_DUQUANT_ABITS=16  # ç¦ç”¨æ¿€æ´»é‡åŒ–ï¼ˆ16bit = no quantï¼‰
```

**ä¼˜ç‚¹ï¼š**
- âœ… ç«‹å³ç”Ÿæ•ˆï¼Œæ— éœ€ä¿®æ”¹ä»£ç 
- âœ… ä»ç„¶æµ‹è¯•æƒé‡é‡åŒ–ï¼ˆW4ï¼‰
- âš ï¸ æ— æ³•æµ‹è¯•å®Œæ•´W4A8

**å½±å“ï¼š**
- åªæµ‹è¯•W4ï¼Œä¸æµ‹è¯•A8
- ç²¾åº¦å¯èƒ½ç•¥å¥½ï¼ˆæ¿€æ´»æœªé‡åŒ–ï¼‰
- ä»èƒ½è·å¾—torch.compileåŠ é€Ÿ

---

### æ–¹æ¡ˆ3: é¢„å…ˆåˆå§‹åŒ–act_scale â­â­â­

**Warmupï¼šåœ¨ç¼–è¯‘å‰åˆå§‹åŒ–æ‰€æœ‰ç¼“å­˜**

ä¿®æ”¹ `enable_duquant_if_configured()`:

```python
def enable_duquant_if_configured(model: nn.Module) -> None:
    # ... åŸæœ‰ä»£ç  ...

    wrap_duquant(model, layer_names, cfg, per_layer_wbits, dry_run=False)

    # NEW: Warmupæ‰€æœ‰DuQuantå±‚
    print("[DUQUANT] Warming up activation scales...")
    with torch.no_grad():
        # åˆ›å»ºdummy input
        dummy_input = torch.randn(1, 1024, device='cuda', dtype=torch.bfloat16)
        for name, module in model.named_modules():
            if isinstance(module, DuQuantLinear):
                # è§¦å‘_get_act_scaleåˆå§‹åŒ–
                _ = module._get_act_scale(dummy_input[:, :module.in_features])
    print("[DUQUANT] Warmup complete!")
```

**ä¼˜ç‚¹ï¼š**
- âœ… åœ¨torch.compileä¹‹å‰å®Œæˆæ‰€æœ‰åˆå§‹åŒ–
- âœ… ä¿æŒå®Œæ•´W4A8

**ç¼ºç‚¹ï¼š**
- âš ï¸ éœ€è¦ä¿®æ”¹ä»£ç 
- âš ï¸ Warmupå¯èƒ½ä¸å‡†ç¡®ï¼ˆdummy dataï¼‰

---

### æ–¹æ¡ˆ4: ç¦ç”¨torch.compile â­

**å›é€€ï¼šå¦‚æœä¿®å¤å¤ªå¤æ‚**

```bash
# ä¿æŒåŸæ ·
export OPENPI_DISABLE_TORCH_COMPILE=1
```

**ä¼˜ç‚¹ï¼š**
- âœ… ç«‹å³ç”Ÿæ•ˆ
- âœ… æ— éœ€ä¿®æ”¹ä»»ä½•ä»£ç 

**ç¼ºç‚¹ï¼š**
- âŒ å¤±å»20-40xåŠ é€Ÿ
- âŒ å›åˆ°åŸæ¥çš„æ…¢é€Ÿåº¦

---

## ğŸ¯ æ¨èä¿®å¤é¡ºåº

### å¿«é€Ÿæµ‹è¯•ï¼ˆ5åˆ†é’Ÿï¼‰

**å…ˆç”¨æ–¹æ¡ˆ2ï¼šç¦ç”¨æ¿€æ´»é‡åŒ–**

```bash
# ç¼–è¾‘ run_optimized_duquant.sh
export OPENPI_DUQUANT_ABITS=16  # æ·»åŠ è¿™è¡Œ

# è¿è¡Œæµ‹è¯•
bash examples/libero/run_optimized_duquant.sh
```

**ç»“æœï¼š**
- å¦‚æœèƒ½æ­£å¸¸è¿è¡Œ â†’ é—®é¢˜ç¡®è®¤ï¼Œåªæ˜¯act_scaleçš„é—®é¢˜
- ä»èƒ½è·å¾—torch.compileåŠ é€Ÿï¼ˆæµ‹è¯•W4ï¼‰

---

### å®Œæ•´ä¿®å¤ï¼ˆ30åˆ†é’Ÿï¼‰

**å®ç°æ–¹æ¡ˆ1ï¼šä¿®æ”¹duquant_layers.py**

æˆ‘ä¼šæä¾›å®Œæ•´çš„patchæ–‡ä»¶ã€‚

---

## ğŸ“ ä¸´æ—¶Workaround

å¦‚æœä½ ç°åœ¨å°±æƒ³è¿è¡Œï¼Œæœ€ç®€å•çš„åŠæ³•ï¼š

```bash
# æ–¹æ³•A: ç¦ç”¨æ¿€æ´»é‡åŒ–ï¼ˆæ¨èï¼‰
export OPENPI_DUQUANT_ABITS=16
bash examples/libero/run_optimized_duquant.sh

# æ–¹æ³•B: ç¦ç”¨torch.compileï¼ˆä¸æ¨èï¼Œå¤±å»åŠ é€Ÿï¼‰
export OPENPI_DISABLE_TORCH_COMPILE=1
bash examples/libero/run_optimized_duquant.sh
```

---

## ğŸ”¬ ä¸ºä»€ä¹ˆregister_bufferæœ‰æ•ˆï¼Ÿ

```python
# æ™®é€šå±æ€§ï¼ˆä¼šæŠ¥é”™ï¼‰
self._act_scale = tensor  # âŒ Mutationï¼Œtorch.compileä¸å…è®¸

# register_bufferï¼ˆtorch.compileå‹å¥½ï¼‰
self.register_buffer("_act_scale", tensor)  # âœ… è¢«è¯†åˆ«ä¸ºæ¨¡å—çŠ¶æ€
self._act_scale.copy_(tensor)  # âœ… In-placeæ›´æ–°ï¼Œä¸æ”¹å˜å¼•ç”¨
```

**å…³é”®å·®å¼‚ï¼š**
- `self.attr = tensor` â†’ æ”¹å˜Pythonå¯¹è±¡çš„å¼•ç”¨ï¼ˆmutationï¼‰
- `self.attr.copy_(tensor)` â†’ in-placeæ›´æ–°tensorå†…å®¹ï¼ˆallowedï¼‰

Torch.compileå…è®¸in-placeæ“ä½œï¼Œä½†ä¸å…è®¸æ”¹å˜å¯¹è±¡å¼•ç”¨ã€‚

---

## ğŸš€ æˆ‘æ¥å¸®ä½ ä¿®å¤

æˆ‘ç°åœ¨å°±å¯ä»¥å¸®ä½ ä¿®æ”¹ä»£ç ï¼Œé€‰æ‹©ï¼š

1. **å¿«é€Ÿæµ‹è¯•**ï¼šæˆ‘å¸®ä½ æ·»åŠ  `OPENPI_DUQUANT_ABITS=16` åˆ°è„šæœ¬
2. **å®Œæ•´ä¿®å¤**ï¼šæˆ‘ä¿®æ”¹ `duquant_layers.py` å®ç°æ–¹æ¡ˆ1

ä½ æƒ³è¦å“ªä¸ªï¼Ÿ
